{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run src/load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install tqdm --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm \n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_train_df = data['adult']['train']['engineered']\n",
    "adult_train_target = data['adult']['train']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_training_set(X_train, y_train, n_pcnt):\n",
    "    n = X_train.shape[0]*n_pcnt//100\n",
    "    return n, X_train[:n], y_train[:n]\n",
    "\n",
    "def time_function_call(function_call):\n",
    "    start = time()\n",
    "    result = function_call\n",
    "    execution_time = time() - start\n",
    "    return result, execution_time\n",
    "\n",
    "def run_model(model, model_name, n_pcnt, data, labels):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, stratify=labels)\n",
    "\n",
    "    \n",
    "    n, X_samp, y_samp = sample_training_set(X_train, y_train, n_pcnt)\n",
    "    \n",
    "    _, fit_time = time_function_call(\n",
    "        model.fit(X_samp, y_samp))\n",
    "    \n",
    "    train_pred, train_pred_time = time_function_call(\n",
    "        model.predict(X_samp))\n",
    "    \n",
    "    test_pred, test_pred_time = time_function_call(\n",
    "        model.predict(X_test))    \n",
    "    \n",
    "    return {\n",
    "            'model' : model,\n",
    "            'model_name' : model_name,\n",
    "            'n_pcnt' : n_pcnt,\n",
    "            'n' : n,\n",
    "            'f1_train_score' : f1_score(y_samp, train_pred),\n",
    "            'f1_test_score' : f1_score(y_test, test_pred),\n",
    "            'accuracy_train_score' : model.score(X_samp, y_samp),\n",
    "            'accuracy_test_score' : model.score(X_test, y_test),\n",
    "            'fit_time' : fit_time,\n",
    "            'train_pred_time' : train_pred_time,\n",
    "            'test_pred_time' : test_pred_time}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Ranking - by Single Feature F$_1$ Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vr_by_f1_test_scores = []\n",
    "for feature in tqdm(adult_train_df.columns):\n",
    "    results = run_model(LogisticRegression(), 'variable ranking', 50, adult_train_df[[feature]], adult_train_target)\n",
    "    test_score = results['f1_test_score']\n",
    "    if test_score > 0:\n",
    "        vr_by_f1_test_scores.append({'feature': feature, 'score' : test_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_by_f1_results = pd.DataFrame(vr_by_f1_test_scores).sort_values('score', ascending=False)\n",
    "vr_by_f1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_by_f1_performant_features = list(vr_by_f1_results.feature.values)\n",
    "vr_by_f1_performant_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the model\n",
    "\n",
    "Add one feature at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_by_f1_features_to_test = []\n",
    "vr_by_f1_features_test_results = {}\n",
    "for feature in tqdm(vr_by_f1_performant_features):\n",
    "    vr_by_f1_features_to_test.append(feature)\n",
    "    vr_by_f1_features_test_results[feature] = run_model(LogisticRegression(), 'logit', 100,\n",
    "                                                        adult_train_df[vr_by_f1_features_to_test],\n",
    "                                                        adult_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_by_f1_features_test_results = pd.DataFrame(vr_by_f1_features_test_results).T\n",
    "vr_by_f1_features_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(vr_by_f1_features_to_test)), vr_by_f1_features_test_results.f1_test_score, label='test performance')\n",
    "plt.plot(range(len(vr_by_f1_features_to_test)), vr_by_f1_features_test_results.f1_train_score, label='train performance')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable-Ranking - By Regression Coefficient in Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_results = run_model(LogisticRegression(), 'logit', 100,\n",
    "                                 adult_train_df,\n",
    "                                 adult_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_logistic_regression_model = simple_model_results['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = simple_logistic_regression_model.coef_\n",
    "features = adult_train_df.columns\n",
    "coefficients = pd.Series(coefficients.T.ravel(), index=features)\n",
    "coefficients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_coefs = np.abs(coefficients).sort_values(ascending=False)\n",
    "sorted_coefs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_by_coef_performant_features = list(sorted_coefs.head(20).index)\n",
    "vr_by_coef_performant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_by_coef_features_to_test = []\n",
    "vr_by_coef_test_results = {}\n",
    "for feature in tqdm(vr_by_coef_performant_features):\n",
    "    vr_by_coef_features_to_test.append(feature)\n",
    "    vr_by_coef_test_results[feature] = run_model(LogisticRegression(), 'logit', 100,\n",
    "                                                 adult_train_df[vr_by_coef_features_to_test],\n",
    "                                                 adult_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_by_coef_test_results = pd.DataFrame(vr_by_coef_test_results).T\n",
    "\n",
    "plt.plot(range(len(vr_by_coef_features_to_test)), vr_by_coef_test_results.f1_test_score, label='test performance')\n",
    "plt.plot(range(len(vr_by_coef_features_to_test)), vr_by_coef_test_results.f1_train_score, label='train performance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_by_coef_with_num_features_to_test = ['age', 'capital-gain','capital-loss','hours-per-week']\n",
    "vr_by_coef_with_num_test_results = {}\n",
    "for feature in tqdm(vr_by_coef_performant_features):\n",
    "    vr_by_coef_with_num_features_to_test.append(feature)\n",
    "    vr_by_coef_with_num_test_results[feature] = run_model(LogisticRegression(), 'logit', 100,\n",
    "                                                          adult_train_df[vr_by_coef_with_num_features_to_test],\n",
    "                                                          adult_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_by_coef_with_num_test_results = pd.DataFrame(vr_by_coef_with_num_test_results).T\n",
    "\n",
    "plt.plot(range(len(vr_by_coef_with_num_features_to_test)-4), vr_by_coef_with_num_test_results.f1_test_score, label='test performance')\n",
    "plt.plot(range(len(vr_by_coef_with_num_features_to_test)-4), vr_by_coef_with_num_test_results.f1_train_score, label='train performance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable-Ranking - By Information Gain in Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dtree_results = run_model(DecisionTreeClassifier(), 'dtree', 100,\n",
    "                                 adult_train_df,\n",
    "                                 adult_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dtree_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_decision_tree_model = simple_dtree_results['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = simple_decision_tree_model.feature_importances_\n",
    "features = adult_train_df.columns\n",
    "feature_importances = pd.Series(feature_importances.T.ravel(), index=features)\n",
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_importances = feature_importances.sort_values(ascending=False)\n",
    "sorted_coefs = np.abs(coefficients).sort_values(ascending=False)\n",
    "sorted_importances = pd.DataFrame(sorted_importances, columns=['importances'])\n",
    "sorted_importances['importance_feature'] = sorted_importances.index\n",
    "sorted_importances.reset_index(drop=True, inplace=True)\n",
    "sorted_coefs = pd.DataFrame(sorted_coefs, columns=['regression coefs'])\n",
    "sorted_coefs['reg_coef_feature'] = sorted_coefs.index\n",
    "sorted_coefs.reset_index(drop=True, inplace=True)\n",
    "sorted_feats = pd.merge(sorted_importances, sorted_coefs, left_index=True, right_index=True)\n",
    "sorted_feats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_performant_features = list(sorted_feats.importance_feature.head(20))\n",
    "importance_performant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_importance_features_to_test = []\n",
    "vr_importance_test_results = {}\n",
    "for feature in tqdm(importance_performant_features):\n",
    "    vr_importance_features_to_test.append(feature)\n",
    "    vr_importance_test_results[feature+'_dtree'] = run_model(DecisionTreeClassifier(), 'dtree', 50,\n",
    "                                                             adult_train_df[vr_importance_features_to_test],\n",
    "                                                             adult_train_target)\n",
    "    vr_importance_test_results[feature+'_logit'] = run_model(LogisticRegression(), 'logit', 50,\n",
    "                                                             adult_train_df[vr_importance_features_to_test],\n",
    "                                                             adult_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_importance_test_results = pd.DataFrame(vr_importance_test_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_results = vr_importance_test_results[vr_importance_test_results.model_name == 'dtree']\n",
    "logit_results = vr_importance_test_results[vr_importance_test_results.model_name == 'logit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,6))\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.plot(range(len(vr_importance_features_to_test)), dtree_results.f1_test_score, label='dtree test performance')\n",
    "plt.plot(range(len(vr_importance_features_to_test)), dtree_results.f1_train_score, label='dtree train performance')\n",
    "plt.legend()\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.plot(range(len(vr_importance_features_to_test)), logit_results.f1_test_score, label='logit test performance')\n",
    "plt.plot(range(len(vr_importance_features_to_test)), logit_results.f1_train_score, label='logit train performance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "fig.add_subplot(1,5,1)\n",
    "plt.plot(range(len(vr_by_f1_features_to_test)), vr_by_f1_features_test_results.f1_test_score, label='test performance')\n",
    "plt.plot(range(len(vr_by_f1_features_to_test)), vr_by_f1_features_test_results.f1_train_score, label='train performance')\n",
    "plt.title('Adding Variable by F1 score\\n as single variable classifier')\n",
    "plt.legend()\n",
    "fig.add_subplot(1,5,2)\n",
    "plt.plot(range(len(vr_by_coef_features_to_test)), vr_by_coef_test_results.f1_test_score, label='test performance')\n",
    "plt.plot(range(len(vr_by_coef_features_to_test)), vr_by_coef_test_results.f1_train_score, label='train performance')\n",
    "plt.title('Adding Variable by reg coef\\n on full model')\n",
    "plt.legend()\n",
    "fig.add_subplot(1,5,3)\n",
    "plt.plot(range(len(vr_by_coef_with_num_features_to_test)-4), vr_by_coef_with_num_test_results.f1_test_score, label='test performance')\n",
    "plt.plot(range(len(vr_by_coef_with_num_features_to_test)-4), vr_by_coef_with_num_test_results.f1_train_score, label='train performance')\n",
    "plt.title('Adding Variable by reg coef\\n on full model\\n(including numerical)')\n",
    "plt.legend()\n",
    "fig.add_subplot(1,5,4)\n",
    "plt.plot(range(len(vr_importance_features_to_test)), dtree_results.f1_test_score, label='dtree test performance')\n",
    "plt.plot(range(len(vr_importance_features_to_test)), dtree_results.f1_train_score, label='dtree train performance')\n",
    "plt.title('Adding Variable by information gain\\n on decision tree')\n",
    "plt.legend()\n",
    "fig.add_subplot(1,5,5)\n",
    "plt.plot(range(len(vr_importance_features_to_test)), logit_results.f1_test_score, label='logit test performance')\n",
    "plt.plot(range(len(vr_importance_features_to_test)), logit_results.f1_train_score, label='logit train performance')\n",
    "plt.title('Adding Variable by information gain\\n on logistic regression')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(range(len(vr_importance_features_to_test)), dtree_results.f1_test_score, label='dtree test performance')\n",
    "plt.plot(range(len(vr_importance_features_to_test)), dtree_results.f1_train_score, label='dtree train performance')\n",
    "plt.title('Adding Variable by information gain\\n on decision tree')\n",
    "plt.xticks(range(len(vr_importance_features_to_test)), vr_importance_features_to_test, rotation='vertical')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(range(len(vr_importance_features_to_test)), logit_results.f1_test_score, label='dtree test performance')\n",
    "plt.plot(range(len(vr_importance_features_to_test)), logit_results.f1_train_score, label='dtree train performance')\n",
    "plt.title('Adding Variable by information gain\\n on logistic regression')\n",
    "plt.xticks(range(len(vr_importance_features_to_test)), vr_importance_features_to_test, rotation='vertical')\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
